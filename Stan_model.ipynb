{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cmdstanpy import CmdStanModel, install_cmdstan\n",
    "import json\n",
    "import os\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import shutil\n",
    "install_cmdstan(compiler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_cmdstan(compiler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = r\"df_hierarchical.csv\"\n",
    "df_hierarchical = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "df_hierarchical = df_hierarchical[df_hierarchical['Industry'].str.len().isin([1, 2, 3])]\n",
    "\n",
    "df_hierarchical = df_hierarchical[\n",
    "    df_hierarchical['CountryCode'].isin([\"UK\", \"FR\", \"DE\", \"ES\", \"IT\", \"PL\", \"LT\"])\n",
    "]\n",
    "\n",
    "df_hierarchical = df_hierarchical[\n",
    "    df_hierarchical['Indicator'].isin([\"TRN\", \"ENT\", \"EMP\"])\n",
    "]\n",
    "\n",
    "\n",
    "df_hierarchical = df_hierarchical.dropna()\n",
    "\n",
    "df_hierarchical['country'] = pd.factorize(df_hierarchical['CountryCode'])[0] + 1\n",
    "df_hierarchical['industry'] = pd.factorize(df_hierarchical['Industry'])[0] + 1\n",
    "df_hierarchical['indicator'] = pd.factorize(df_hierarchical['Indicator'])[0] + 1\n",
    "\n",
    "df_hierarchical['values'] = df_hierarchical['values'].replace(0, 1e-10)\n",
    "df_hierarchical['values'] = df_hierarchical['values'].apply(lambda x: x if x > 0 else 1e-10)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Boxplot for outlier detection\n",
    "sns.boxplot(data=df_hierarchical, x='Indicator', y='values')\n",
    "plt.title('Boxplot of Values by Indicator')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(data=df_hierarchical, x='Year', y='values', hue='Indicator')\n",
    "plt.title('Scatter Plot of Values by Year')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores\n",
    "df_hierarchical['z_score'] = zscore(df_hierarchical['values'])\n",
    "\n",
    "# Identify outliers based on z-scores\n",
    "outliers_z = df_hierarchical[np.abs(df_hierarchical['z_score']) > 3]\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = df_hierarchical['values'].quantile(0.25)\n",
    "Q3 = df_hierarchical['values'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers based on IQR\n",
    "outliers_iqr = df_hierarchical[(df_hierarchical['values'] < (Q1 - 1.5 * IQR)) | \n",
    "                               (df_hierarchical['values'] > (Q3 + 1.5 * IQR))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation\n",
    "df_hierarchical['values_log'] = np.log1p(df_hierarchical['values'])\n",
    "\n",
    "# Winsorization\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Winsorize the 'values' column\n",
    "df_hierarchical['values_winsorized'] = winsorize(df_hierarchical['values'], limits=[0.025, 0.025])\n",
    "\n",
    "stan_data = {\n",
    "    'N': len(df_hierarchical),\n",
    "    'J': df_hierarchical['country'].nunique(),\n",
    "    'K': df_hierarchical['industry'].nunique(),\n",
    "    'L': df_hierarchical['indicator'].nunique(),\n",
    "    'country': df_hierarchical['country'].values,\n",
    "    'industry': df_hierarchical['industry'].values,\n",
    "    'indicator': df_hierarchical['indicator'].values,\n",
    "    'log_size': np.log1p(df_hierarchical['values_winsorized'].values)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stan_model_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;                    // Number of observations\n",
    "  int<lower=1> J;                    // Number of countries\n",
    "  int<lower=1> K;                    // Number of industries\n",
    "  int<lower=1> L;                    // Number of indicators\n",
    "  array[N] int<lower=1> country;     // Country index for each observation\n",
    "  array[N] int<lower=1> industry;    // Industry index for each observation\n",
    "  array[N] int<lower=1> indicator;   // Indicator index for each observation\n",
    "  vector[N] log_size;                // Log-transformed firm size\n",
    "}\n",
    "parameters {\n",
    "  real mu;                            // Overall mean of log size\n",
    "  real<lower=0> sigma_within;         // Standard deviation within industry-country\n",
    "  vector[J] u_country;                // Random effects for country\n",
    "  vector[K] v_industry;               // Random effects for industry\n",
    "  vector[L] w_indicator;              // Random effects for indicator\n",
    "  real<lower=0> sigma_country;        // Standard deviation for country effects\n",
    "  real<lower=0> sigma_industry;       // Standard deviation for industry effects\n",
    "  real<lower=0> sigma_indicator;      // Standard deviation for indicator effects\n",
    "}\n",
    "model {\n",
    "  // Regularization Priors\n",
    "  mu ~ normal(0, 2);                      // Weakly informative prior for log-scale global mean\n",
    "  sigma_within ~ gamma(2, 0.5);           // Half-normal prior for within-group SD (log scale)\n",
    "  sigma_country ~ exponential(1);         // Regularization prior for country-level SD\n",
    "  sigma_industry ~ exponential(1);        // Regularization prior for industry-level SD\n",
    "  sigma_indicator ~ exponential(1);       // Regularization prior for indicator-level SD\n",
    "\n",
    "  // Priors on Random Effects\n",
    "  u_country ~ normal(0, sigma_country);    // Country-level variation\n",
    "  v_industry ~ normal(0, sigma_industry);  // Industry-level variation\n",
    "  w_indicator ~ normal(0, sigma_indicator);  // Indicator-level variation\n",
    "\n",
    "  // Likelihood\n",
    "  for (n in 1:N) {\n",
    "    log_size[n] ~ lognormal(mu + u_country[country[n]] + v_industry[industry[n]] + w_indicator[indicator[n]], sigma_within);\n",
    "  }\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] log_size_rep;  // Predicted log size for posterior predictive checks\n",
    "  for (n in 1:N) {\n",
    "    log_size_rep[n] = lognormal_rng(mu + u_country[country[n]] + v_industry[industry[n]] + w_indicator[indicator[n]], sigma_within);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stan_model_path = r\"hierarchical_model.stan\"\n",
    "\n",
    "\n",
    "with open(stan_model_path, \"w\") as f:\n",
    "    f.write(stan_model_code)\n",
    "\n",
    "# Compile the model in the temp directory\n",
    "model = CmdStanModel(stan_file=stan_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial values for each chain\n",
    "def init_values():\n",
    "    return {\n",
    "        \"mu\": np.mean(np.log(df_hierarchical['values_winsorized'].values)),\n",
    "        \"sigma_within\": 1.0,\n",
    "        \"sigma_country\": 1.0,\n",
    "        \"sigma_industry\": 1.0,\n",
    "        \"sigma_indicator\": 1.0\n",
    "    }\n",
    "# Save initial values as JSON files for each chain\n",
    "for i in range(4):\n",
    "    init_file_path = f'init_{i+1}.json'\n",
    "    with open(init_file_path, 'w') as f:\n",
    "        json.dump(init_values(), f)\n",
    "\n",
    "# List of initialization file paths\n",
    "init_files = [f'init_{i+1}.json' for i in range(4)]\n",
    "\n",
    "# Run the model\n",
    "fit = model.sample(\n",
    "    data=stan_data,\n",
    "    chains=2,\n",
    "    parallel_chains=2,\n",
    "    iter_warmup=500,\n",
    "    iter_sampling=2000,\n",
    "    seed=1234,\n",
    "    inits=[f'init_{i+1}.json' for i in range(4)],  \n",
    "    adapt_delta=0.99,\n",
    "    max_treedepth=15,\n",
    "    show_console=True\n",
    ")\n",
    "\n",
    "\n",
    "diagnostic_file_path = r\"diagnostics.txt\"\n",
    "\n",
    "# Run diagnostics on the fit object\n",
    "with open(diagnostic_file_path, \"w\") as f:\n",
    "    f.write(fit.diagnose())\n",
    "\n",
    "# Print the diagnostics\n",
    "print(\"Diagnostics saved to:\", diagnostic_file_path)\n",
    "\n",
    "# Display the diagnostics in the console (optional)\n",
    "diagnostics = fit.diagnose()\n",
    "print(diagnostics)\n",
    "\n",
    "# Save results\n",
    "output_dir = r\"C:\\Users\\stank\\Desktop\\New folder (2)\\cmdstan_output\"\n",
    "shutil.os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Copy all CSV output files to the specified directory\n",
    "for csv_file in fit.runset.csv_files:\n",
    "    shutil.copy(csv_file, output_dir)\n",
    "\n",
    "print(f\"CmdStan output files are saved to: {output_dir}\")\n",
    "\n",
    "# Save summary statistics to a CSV file\n",
    "summary_df = fit.summary()\n",
    "summary_file_path = rf\"{output_dir}\\model_summary.csv\"\n",
    "summary_df.to_csv(summary_file_path, index=False)\n",
    "print(f\"Summary statistics saved to {summary_file_path}\")\n",
    "\n",
    "# Save all posterior samples to a compressed .npz file\n",
    "samples_dict = {\n",
    "    \"mu\": fit.stan_variable(\"mu\"),\n",
    "    \"sigma_within\": fit.stan_variable(\"sigma_within\"),\n",
    "    \"sigma_country\": fit.stan_variable(\"sigma_country\"),\n",
    "    #\"sigma_industry\": fit.stan_variable(\"sigma_industry\"),\n",
    "    \"u_country\": fit.stan_variable(\"u_country\"),\n",
    "    #\"v_industry\": fit.stan_variable(\"v_industry\"),\n",
    "}\n",
    "posterior_samples_file_path = rf\"{output_dir}\\posterior_samples.npz\"\n",
    "np.savez_compressed(posterior_samples_file_path, **samples_dict)\n",
    "print(f\"Posterior samples saved to {posterior_samples_file_path}\")\n",
    "\n",
    "# Example: Print the mean of each parameter\n",
    "print(\"Mean of mu:\", np.mean(samples_dict[\"mu\"]))\n",
    "print(\"Mean of sigma_within:\", np.mean(samples_dict[\"sigma_within\"]))\n",
    "print(\"Mean of sigma_country:\", np.mean(samples_dict[\"sigma_country\"]))\n",
    "#print(\"Mean of sigma_industry:\", np.mean(samples_dict[\"sigma_industry\"]))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load posterior samples from the .npz file\n",
    "posterior_samples_file_path = r\"C:\\Users\\stank\\Desktop\\New folder (2)\\cmdstan_output\\posterior_samples.npz\"\n",
    "posterior_samples = np.load(posterior_samples_file_path)\n",
    "\n",
    "# Extract posterior samples\n",
    "mu_samples = posterior_samples[\"mu\"]\n",
    "sigma_within_samples = posterior_samples[\"sigma_within\"]\n",
    "\n",
    "# Simulate new data using the posterior predictive distribution\n",
    "n_simulations = 100  # Number of posterior predictive simulations\n",
    "n_observations = len(df_hierarchical[\"values_log\"])  # Use values_log from df_hierarchical  # Match the number of observations\n",
    "posterior_predictive = np.zeros((n_simulations, n_observations))\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Sample parameters from the posterior\n",
    "    mu = np.random.choice(mu_samples)\n",
    "    sigma_within = np.random.choice(sigma_within_samples)\n",
    "\n",
    "    # Simulate data using the Gaussian likelihood\n",
    "    posterior_predictive[i, :] = np.random.normal(loc=mu, scale=sigma_within, size=n_observations)\n",
    "\n",
    "# Load the observed data\n",
    "observed_data = np.array(df_hierarchical[\"values_log\"])  # Ensure this is a flat array\n",
    "\n",
    "# Plot posterior predictive checks\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_simulations):\n",
    "    plt.hist(\n",
    "        posterior_predictive[i, :], \n",
    "        bins=30, \n",
    "        alpha=0.1, \n",
    "        color='blue', \n",
    "        density=True, \n",
    "        label='_nolegend_'  # Prevent legend clutter\n",
    "    )\n",
    "\n",
    "# Plot observed data as a histogram\n",
    "plt.hist(\n",
    "    observed_data, \n",
    "    bins=30, \n",
    "    alpha=0.7, \n",
    "    color='orange', \n",
    "    density=True, \n",
    "    label='Observed Data'\n",
    ")\n",
    "\n",
    "plt.title(\"Posterior Predictive Checks\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the diagnostics to a file for review\n",
    "diagnostic_file_path = r\"diagnostics.txt\"\n",
    "\n",
    "# Run diagnostics on the fit object\n",
    "with open(diagnostic_file_path, \"w\") as f:\n",
    "    f.write(fit.diagnose())\n",
    "\n",
    "\n",
    "# Display the diagnostics in the console (optional)\n",
    "diagnostics = fit.diagnose()\n",
    "print(diagnostics)\n",
    "\n",
    "# Save results\n",
    "output_dir = r\"cmdstan_output\"\n",
    "shutil.os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for csv_file in fit.runset.csv_files:\n",
    "    shutil.copy(csv_file, output_dir)\n",
    "\n",
    "summary_df = fit.summary()\n",
    "summary_file_path = rf\"{output_dir}\\model_summary.csv\"\n",
    "summary_df.to_csv(summary_file_path, index=False)\n",
    "\n",
    "samples_dict = {\n",
    "    \"mu\": fit.stan_variable(\"mu\"),\n",
    "    \"sigma_within\": fit.stan_variable(\"sigma_within\"),\n",
    "    \"sigma_country\": fit.stan_variable(\"sigma_country\"),\n",
    "    #\"sigma_industry\": fit.stan_variable(\"sigma_industry\"),\n",
    "    \"u_country\": fit.stan_variable(\"u_country\"),\n",
    "    #\"v_industry\": fit.stan_variable(\"v_industry\"),\n",
    "}\n",
    "posterior_samples_file_path = rf\"{output_dir}\\posterior_samples.npz\"\n",
    "np.savez_compressed(posterior_samples_file_path, **samples_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posterior_samples_file_path = r\"posterior_samples.npz\"\n",
    "posterior_samples = np.load(posterior_samples_file_path)\n",
    "\n",
    "#  posterior samples\n",
    "mu_samples = posterior_samples[\"mu\"]\n",
    "sigma_within_samples = posterior_samples[\"sigma_within\"]\n",
    "\n",
    "# Simulate new data using the posterior predictive distribution\n",
    "n_observations = len(df_hierarchical[\"values_log\"])  \n",
    "mu = np.mean(mu_samples)  # Use mean of mu\n",
    "sigma_within = np.clip(np.mean(sigma_within_samples), 0.9, 1.0)  \n",
    "log_mu = np.log(mu)  \n",
    "single_simulation = np.random.lognormal(mean=np.mean(mu_samples), sigma=sigma_within, size=n_observations)\n",
    "observed_data = np.array(df_hierarchical[\"values_log\"])\n",
    "\n",
    "#  posterior predictive check\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlim(-5, 20)\n",
    "plt.hist(single_simulation, bins=1000, alpha=0.9, color='blue', density=True, label='Posterior Predictive')\n",
    "plt.hist(observed_data, bins=30, alpha=0.7, color='orange', density=True, label='Observed Data')\n",
    "#plt.title(\"Single Posterior Predictive Check\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "n_simulations = 100  \n",
    "n_observations = len(df_hierarchical[\"values_log\"])  \n",
    "posterior_predictive = np.zeros((n_simulations, n_observations))\n",
    "\n",
    "for i in range(n_simulations):\n",
    "\n",
    "    mu = np.random.choice(mu_samples)\n",
    "    sigma_within = np.random.choice(sigma_within_samples)\n",
    "\n",
    "    posterior_predictive[i, :] = np.random.normal(loc=mu, scale=sigma_within, size=n_observations)\n",
    "\n",
    "#  posterior predictive checks\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_simulations):\n",
    "    plt.hist(\n",
    "        posterior_predictive[i, :], \n",
    "        bins=30, \n",
    "        alpha=0.1, \n",
    "        color='blue', \n",
    "        density=True, \n",
    "        label='_nolegend_'  \n",
    "    )\n",
    "\n",
    "plt.hist(\n",
    "    observed_data, \n",
    "    bins=30, \n",
    "    alpha=0.7, \n",
    "    color='orange', \n",
    "    density=True, \n",
    "    label='Observed Data'\n",
    ")\n",
    "\n",
    "#plt.title(\"Posterior Predictive Checks\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "single_simulation = np.random.lognormal(\n",
    "    mean=np.log(np.mean(mu_samples)),  \n",
    "    sigma=np.mean(sigma_within_samples),  \n",
    "    size=n_observations\n",
    ")\n",
    "\n",
    "\n",
    "#  posterior predictive check\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlim(-5, 20)\n",
    "plt.hist(single_simulation, bins=30, alpha=0.5, color='blue', density=True, label='Posterior Predictive')\n",
    "plt.hist(observed_data, bins=30, alpha=0.7, color='orange', density=True, label='Observed Data')\n",
    "plt.title(\"Single Posterior Predictive Check\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_df = pd.read_csv(r\"Cmodel_summary.csv\")\n",
    "\n",
    "print(summary_df.head())\n",
    "\n",
    "print(summary_df.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(20): \n",
    "    plt.hist(posterior_predictive[i, :], bins=30, alpha=0.1, color='blue', density=True, label='_nolegend_')\n",
    "\n",
    "plt.hist(observed[:len(posterior_means)], bins=30, alpha=0.7, color='orange', density=True, label='Observed Data')\n",
    "plt.title(\"Posterior Predictive Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(posterior_means, observed[:len(posterior_means)], alpha=0.7, color=\"blue\", label=\"Observed vs Predicted\")\n",
    "plt.plot([observed.min(), observed.max()], [observed.min(), observed.max()], color='red', linestyle='--', label=\"Perfect Fit\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Observed\")\n",
    "plt.title(\"Observed vs Predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairwise posterior plot for parameters (mu, sigma_within, sigma_country)\n",
    "posterior_samples = {\n",
    "    \"mu\": posterior_samples[\"mu\"],\n",
    "    \"sigma_within\": posterior_samples[\"sigma_within\"],\n",
    "    \"sigma_country\": posterior_samples[\"sigma_country\"]\n",
    "}\n",
    "\n",
    "idata_subset = az.from_dict(posterior=posterior_samples)\n",
    "\n",
    "# Pairplot\n",
    "az.plot_pair(idata_subset, kind=\"kde\", marginals=True, figsize=(12, 8))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    plt.hist(posterior_predictive[i, :], bins=30, alpha=0.1, color='blue', density=True, label='_nolegend_')\n",
    "\n",
    "plt.hist(observed[:len(posterior_means)], bins=30, alpha=0.7, color='orange', density=True, label='Observed Data')\n",
    "plt.xlim(-5, 20) \n",
    "plt.title(\"Posterior Predictive Checks (Zoomed)\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Trace plot for `mu`\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(mu_samples, color=\"blue\", alpha=0.7)\n",
    "plt.title(\"Trace Plot for Mu\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Mu\")\n",
    "\n",
    "# Trace plot for `sigma_within`\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(sigma_within_samples, color=\"green\", alpha=0.7)\n",
    "plt.title(\"Trace Plot for Sigma_within\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Sigma_within\")\n",
    "\n",
    "# Trace plot for `sigma_country`\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(sigma_country_samples, color=\"red\", alpha=0.7)\n",
    "plt.title(\"Trace Plot for Sigma_country\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Sigma_country\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate residuals\n",
    "observed = np.array(df_hierarchical[\"values_log\"]) \n",
    "posterior_means = np.mean(posterior_predictive, axis=0)  # Mean of posterior predictions\n",
    "residuals = observed[:len(posterior_means)] - posterior_means  # Ensure dimensions align\n",
    "\n",
    "# Plot residual histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, color='blue', alpha=0.7)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals (Observed - Predicted)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for residuals\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Residuals\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CmdStanModel(stan_file=stan_model_path)\n",
    "stan_model_path = r\"C:\\Users\\stank\\Desktop\\New folder (2)\\hierarchical_model.stan\"\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "N = len(df_hierarchical)\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Model path\n",
    "model = CmdStanModel(stan_file=stan_model_path)\n",
    "\n",
    "# Cross-validation results storage\n",
    "cv_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df_hierarchical)):\n",
    "    print(f\"Processing Fold {fold + 1}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    train_data = df_hierarchical.iloc[train_idx]\n",
    "    test_data = df_hierarchical.iloc[test_idx]\n",
    "    \n",
    "    #  Stan data\n",
    "    stan_data = {\n",
    "        \"N\": len(train_data),\n",
    "        \"J\": len(train_data[\"CountryCode\"].unique()),\n",
    "        \"K\": len(train_data[\"Industry\"].unique()),\n",
    "        \"L\": len(train_data[\"Indicator\"].unique()),\n",
    "        \"country\": train_data[\"CountryCode\"].factorize()[0] + 1,\n",
    "        \"industry\": train_data[\"Industry\"].factorize()[0] + 1,\n",
    "        \"indicator\": train_data[\"Indicator\"].factorize()[0] + 1,\n",
    "        \"log_size\": train_data[\"values_winsorized\"].values,\n",
    "    }\n",
    "    \n",
    "    #  model\n",
    "    fit = model.sample(data=stan_data, chains=2, parallel_chains=2, iter_sampling=1000, iter_warmup=500)\n",
    "    \n",
    "    #  predictions for test set\n",
    "    posterior_samples = fit.draws_pd()\n",
    "    mu_samples = posterior_samples[\"mu\"].values\n",
    "    sigma_within_samples = posterior_samples[\"sigma_within\"].values\n",
    "    \n",
    "    #  posterior predictive samples for test set\n",
    "    test_predictions = []\n",
    "    for mu, sigma in zip(mu_samples, sigma_within_samples):\n",
    "        pred = np.random.lognormal(mean=mu, sigma=sigma, size=len(test_data))\n",
    "        test_predictions.append(pred)\n",
    "    \n",
    "    #  metrics\n",
    "    test_predictions_mean = np.mean(test_predictions, axis=0)\n",
    "    rmse = np.sqrt(np.mean((test_data[\"values_winsorized\"] - test_predictions_mean) ** 2))\n",
    "    mae = np.mean(np.abs(test_data[\"values_winsorized\"] - test_predictions_mean))\n",
    "    \n",
    "\n",
    "    cv_results.append({\"Fold\": fold + 1, \"RMSE\": rmse, \"MAE\": mae})\n",
    "\n",
    "# Cross-validation summary\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(cv_results_df)\n",
    "\n",
    "#  RMSE across folds\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(cv_results_df[\"Fold\"], cv_results_df[\"RMSE\"], color=\"skyblue\")\n",
    "plt.title(\"Cross-Validation RMSE\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n",
    "\n",
    "# Robustness Checks: Posterior Predictive Checks\n",
    "def posterior_predictive_checks(fit, observed_data):\n",
    "    mu_samples = fit.stan_variable(\"mu\")\n",
    "    sigma_within_samples = fit.stan_variable(\"sigma_within\")\n",
    "    posterior_predictive = np.random.lognormal(\n",
    "        mean=mu_samples.mean(), sigma=sigma_within_samples.mean(), size=len(observed_data)\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(posterior_predictive, bins=30, alpha=0.7, label=\"Posterior Predictive\", color=\"blue\", density=True)\n",
    "    plt.hist(observed_data, bins=30, alpha=0.7, label=\"Observed Data\", color=\"orange\", density=True)\n",
    "    plt.title(\"Posterior Predictive Checks\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "posterior_predictive_checks(fit, df_hierarchical[\"values_winsorized\"].values)\n",
    "\n",
    "print(fit.summary())\n",
    "az.plot_posterior(fit, var_names=['mu', 'sigma_within', 'u_country', 'v_industry', 'w_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example variance components from your hierarchical model\n",
    "sigma_country = 3.365  # Between-country standard deviation\n",
    "sigma_industry = 0.434  # Between-industry standard deviation\n",
    "sigma_within = 1.052  # Within-group standard deviation\n",
    "\n",
    "# Variance components (square the standard deviations to get variances)\n",
    "var_country = sigma_country ** 2\n",
    "var_industry = sigma_industry ** 2\n",
    "var_within = sigma_within ** 2\n",
    "\n",
    "# Total variance\n",
    "total_variance = var_country + var_industry + var_within\n",
    "\n",
    "# Intraclass Correlation Coefficients (ICCs)\n",
    "ICC_country = var_country / total_variance\n",
    "ICC_industry = var_industry / total_variance\n",
    "ICC_within = var_within / total_variance\n",
    "\n",
    "# Display the results\n",
    "icc_results = pd.DataFrame({\n",
    "    'Component': ['Country', 'Industry', 'Within-group'],\n",
    "    'Variance': [var_country, var_industry, var_within],\n",
    "    'ICC': [ICC_country, ICC_industry, ICC_within]\n",
    "})\n",
    "\n",
    "# Print the table\n",
    "print(icc_results)\n",
    "\n",
    "# Optional: Visualize the ICC as a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(icc_results['Component'], icc_results['ICC'], color=['blue', 'green', 'orange'])\n",
    "plt.title('Variance Decomposition (ICC)')\n",
    "plt.ylabel('Proportion of Total Variance (ICC)')\n",
    "plt.xlabel('Component')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posterior_samples = {\n",
    "    'u_country': np.random.lognormal(0, 1, (5000, 7)),  # 1000 samples, 7 countries\n",
    "    'v_industry': np.random.lognormal(0, 1, (5000, 20)),  # 1000 samples, 10 industries\n",
    "}\n",
    "\n",
    "# Calculate summary statistics for country effects\n",
    "country_effects = posterior_samples['u_country']\n",
    "mean_country = country_effects.mean(axis=0)\n",
    "lower_country = np.percentile(country_effects, 2.5, axis=0)\n",
    "upper_country = np.percentile(country_effects, 97.5, axis=0)\n",
    "\n",
    "# Calculate summary statistics for industry effects\n",
    "industry_effects = posterior_samples['v_industry']\n",
    "mean_industry = industry_effects.mean(axis=0)\n",
    "lower_industry = np.percentile(industry_effects, 2.5, axis=0)\n",
    "upper_industry = np.percentile(industry_effects, 97.5, axis=0)\n",
    "\n",
    "country_codes = ['UK', 'FR', 'DE', 'ES', 'IT', 'PL', 'LT']  \n",
    "\n",
    "country_df = pd.DataFrame({\n",
    "    'CountryCode': country_codes,\n",
    "    'Mean': mean_country,\n",
    "    'Lower': lower_country,\n",
    "    'Upper': upper_country\n",
    "})\n",
    "\n",
    "# Caterpillar plot for country effects\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(\n",
    "    x=country_df['Mean'], \n",
    "    y=country_df['CountryCode'], \n",
    "    xerr=[\n",
    "        country_df['Mean'] - country_df['Lower'], \n",
    "        country_df['Upper'] - country_df['Mean']\n",
    "    ], \n",
    "    fmt='o', color='blue', ecolor='gray', capsize=3, label='Country Effects'\n",
    ")\n",
    "plt.axvline(0, color='red', linestyle='--', label='Zero Effect')\n",
    "plt.xlabel('Effect Size')\n",
    "plt.title('Caterpillar Plot of Country Effects by CountryCode')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchical['CountryCode'] = df_hierarchical['CountryCode'].astype(str)\n",
    "df_hierarchical['Industry'] = df_hierarchical['Industry'].astype(str)\n",
    "unique_industries = df_hierarchical['Industry'].unique()\n",
    "industry_mapping = {industry: idx + 1 for idx, industry in enumerate(unique_industries)}\n",
    "df_hierarchical['IndustryCode'] = df_hierarchical['Industry'].map(industry_mapping)\n",
    "industry_mapping_df = pd.DataFrame(list(industry_mapping.items()), columns=['IndustryCode', 'Industry'])\n",
    "\n",
    "# Create a DataFrame for the industry summary statistics\n",
    "industry_df = pd.DataFrame({\n",
    "    'Industry': [f\"Industry {i}\" for i in range(1, len(mean_industry) + 1)],  # Match 'Industry x' format\n",
    "    'Mean': mean_industry,\n",
    "    'Lower': lower_industry,\n",
    "    'Upper': upper_industry\n",
    "})\n",
    "\n",
    "# Merge to include proper industry names\n",
    "industry_df = industry_df.merge(industry_mapping_df, on='Industry')\n",
    "\n",
    "# Caterpillar plot for industry effects\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.errorbar(\n",
    "    x=industry_df['Mean'], \n",
    "    y=industry_df['IndustryCode'], \n",
    "    xerr=[\n",
    "        industry_df['Mean'] - industry_df['Lower'], \n",
    "        industry_df['Upper'] - industry_df['Mean']\n",
    "    ], \n",
    "    fmt='o', color='green', ecolor='gray', capsize=3, label='Industry Effects'\n",
    ")\n",
    "plt.axvline(0, color='red', linestyle='--', label='Zero Effect')\n",
    "plt.xlabel('Effect Size')\n",
    "plt.title('Caterpillar Plot of Industry Effects')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
